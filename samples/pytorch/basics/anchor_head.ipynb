{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_x: tensor([  0.,   1.,   2.,  ..., 637., 638., 639.], device='cuda:0')\n",
      "lin_y: tensor([  0.,   0.,   0.,  ..., 383., 383., 383.], device='cuda:0')\n",
      "anchors_w tensor([[1.6250],\n",
      "        [4.0000],\n",
      "        [7.3750]], device='cuda:0')\n",
      "anchors_h tensor([[1.5000],\n",
      "        [3.6250],\n",
      "        [6.5000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "nW = 640\n",
    "nH = 384\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "lin_x = torch.linspace(0, nW - 1, nW).to(device).repeat(nH, 1).view(nH * nW)\n",
    "lin_y = torch.linspace(0, nH - 1, nH).to(device).repeat(nW, 1).t().contiguous().view(nH * nW)\n",
    "print('lin_x:', lin_x)\n",
    "print('lin_y:', lin_y)\n",
    "\n",
    "'''\n",
    "anchors of different size for different feature maps\n",
    "the featur maps sizes are respectively 1/32, 1/16, 1/8 of the original image size\n",
    "(13,12), (32,29), (59,52) anchors sizes are mapped to the 1/8 feature map\n",
    "(95,80), (90,173), (147, 118) anchors sizes are mapped to the 1/16 feature map\n",
    "(197,180), (177,303), (380,269) anchors sizes are mapped to the 1/32 feature map\n",
    "each feature map has 3 different size of anchors\n",
    "'''\n",
    "anchors=[(13,12), (32,29), (59,52),\n",
    "            (95,80), (90,173), (147, 118),\n",
    "                (197,180), (177,303), (380,269)]\n",
    "anchors_mask_all=[(6,7,8), (3,4,5), (0,1,2)]\n",
    "num_anchors = len(anchors_mask_all)\n",
    "anchors_mask = anchors_mask_all[2]\n",
    "nA = num_anchors\n",
    "reduction = 8\n",
    "anchors = torch.Tensor(anchors) / reduction\n",
    "anchors = anchors.to(device)\n",
    "anchors_w = anchors[anchors_mask, 0].view(nA, 1).to(device)\n",
    "anchors_h = anchors[anchors_mask, 1].view(nA, 1).to(device)\n",
    "print('anchors_w', anchors_w)\n",
    "print('anchors_h', anchors_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6250,  1.5000],\n",
      "        [ 4.0000,  3.6250],\n",
      "        [ 7.3750,  6.5000],\n",
      "        [11.8750, 10.0000],\n",
      "        [11.2500, 21.6250],\n",
      "        [18.3750, 14.7500],\n",
      "        [24.6250, 22.5000],\n",
      "        [22.1250, 37.8750],\n",
      "        [47.5000, 33.6250]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(anchors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
